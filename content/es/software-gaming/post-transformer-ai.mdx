---
title: "Post-transformer AI - que viene despues de los LLM clasicos"
description: "Baby Dragon Hatchling de Pathway y las nuevas arquitecturas post-transformer prometen una IA que aprende sobre la marcha, recuerda a largo plazo y cambia como creamos juegos, agentes y software."
date: "2025-12-02"
category: "software-gaming"
image: "/images/software-gaming/post-transformer-ai-hero.jpg"
author: "InfoHelm Team"
hero: "/images/software-gaming/post-transformer-ai-hero.jpg"
heroAlt: "Red neuronal abstracta con un dragon luminoso que simboliza una nueva arquitectura de IA"
tags:
  - "software-gaming"
  - "ai"
  - "post-transformer"
  - "llm"
---

# Post-transformer AI: qué viene después de los LLM clásicos

En los últimos años hemos vivido en la **“era de los transformers”**: la arquitectura que está detrás de ChatGPT, Claude, Gemini y un sinfín de modelos más pequeños. Prácticamente todo lo que llamamos *LLM* es alguna variante de transformer: una red enorme que lee tokens, calcula atención y predice la siguiente palabra.

Pero a medida que los modelos crecen, nos topamos con un muro:

- la ventana de contexto sigue siendo limitada,
- los modelos no tienen memoria real a largo plazo, solo un **“buffer” temporal de contexto**,
- el aprendizaje es **offline**: se entrena durante meses y luego se “congela”,
- cada salto de tamaño exige cantidades brutales de GPUs y energía.

Por eso cada vez se habla más de arquitecturas **“post-transformer”**: una nueva generación de modelos que conservan lo bueno de los transformers (calidad, escalado), pero añaden **memoria integrada, aprendizaje continuo y mucha más eficiencia**.

Uno de los intentos más llamativos en esta dirección es **Baby Dragon Hatchling (BDH)** de la empresa Pathway: una arquitectura que ellos mismos etiquetan como *post-Transformer* e inspirada directamente en cómo funciona el cerebro humano.

![Red neuronal abstracta y un dragón de luz](/images/software-gaming/post-transformer-ai-hero.jpg)

## Repaso rápido: qué son los transformers y dónde se rompen

En 2017 los transformers sustituyeron a los viejos modelos RNN/LSTM y trajeron dos ideas clave:

1. **Atención (attention)** – en lugar de leer tokens estrictamente en secuencia como una RNN, el modelo en cada capa mira todo el contexto y decide qué es importante.
2. **Paralelismo** – es posible entrenar modelos enormes en miles de GPUs porque los tokens se procesan en lotes.

Eso nos llevó a los LLM que usamos hoy: grandes modelos de decodificador (estilo GPT) entrenados con miles de millones o billones de tokens.

Pero los transformers también tienen **debilidades estructurales**:

- **El contexto es una ventana deslizante** – aunque estés escribiendo un libro de 300 páginas, el modelo solo ve unos cuantos miles de tokens a la vez. Cuanto más grande la ventana, más caro es el cómputo.
- **No hay memoria de verdad** – cada consulta es como una escena nueva. El modelo no “te recuerda” como persona a menos que los desarrolladores añadan sistemas de memoria externos.
- **Olvido catastrófico** – si intentas seguir entrenando el modelo con datos nuevos, el conocimiento antiguo puede degradarse fácilmente.
- **Todo está en un mismo bloque monolítico** – conocimiento del mundo, memoria de trabajo y razonamiento se mezclan en el mismo conjunto de parámetros.

En la práctica esto significa:

- un NPC impulsado por un LLM que hoy actúa como **sabio mago anciano**, mañana puede sonar como **promotor de criptos** en la misma ciudad, porque no existe personalidad ni memoria estables,
- un co-piloto de IA en tu IDE olvida lo que hiciste la semana pasada y empieza desde cero cada vez,
- agentes que parecen listos en una sesión larga, pero al día siguiente hay que **reempacar todo el contexto** en el prompt.

Por eso cada vez más investigación busca **arquitecturas con memoria explícita y más estructura**: algo entre cerebro y software clásico.

## Baby Dragon Hatchling: un “cerebro dragón” con memoria integrada

Pathway es un equipo pequeño pero agresivo de Palo Alto que afirma haber creado “el eslabón perdido entre transformers y modelos tipo cerebro”. Su arquitectura **Baby Dragon Hatchling (BDH)** se describe como:

- una **red de “partículas neuronales”** que se comunican localmente (en lugar de atención global sobre todos los tokens),
- un **grafo libre de escala** – algunos nodos son grandes hubs, la mayoría tiene pocas conexiones, similar a redes neuronales biológicas,
- **memoria de trabajo basada en plasticidad sináptica** – las conexiones se fortalecen o debilitan *temporalmente* durante el razonamiento,
- una separación clara entre **parámetros a largo plazo y estado a corto plazo**.

En lenguaje llano:

- en lugar de que cada token “mire” a todos los demás a través del costoso mecanismo de atención, BDH usa **interacciones locales** en un grafo,
- **la memoria no es solo una secuencia de tokens**, sino cambios en las propias conexiones durante una ventana corta de tiempo, como “huellas” en el cerebro,
- la arquitectura está pensada para ser **más interpretable**: se puede seguir qué partes del grafo cargan qué tipo de información.

Los primeros experimentos indican que BDH:

- puede alcanzar **un nivel de calidad similar a GPT-2** en lenguaje y traducción con un número comparable de parámetros,
- mantiene un **escalado tipo transformer** – más datos y cómputo siguen aportando mejor rendimiento,
- abre la puerta a **razonamiento algorítmico** y memoria más larga sin ventanas de contexto gigantes.

No estamos hablando de un modelo que vaya a sustituir a GPT-4/5 en producción mañana mismo, pero como **arquitectura** BDH es interesante porque:

- **separa explícitamente la memoria del modelo central**,  
- intenta imitar **principios biológicos (aprendizaje hebbiano, redes libre de escala)**,  
- está diseñado desde el inicio para **adaptarse en tiempo real y aprender a lo largo de la vida**.

## Qué significa esto para los juegos y los NPC

¿Por qué meter todo esto en la categoría **software-gaming** y no en “teoría de IA” pura?

Porque los **videojuegos** pueden ser uno de los primeros lugares donde las ideas post-transformer se noten mucho.

Imagina un mundo donde:

- un NPC **recuerda de verdad** todos tus encuentros anteriores, no como una simple línea de log, sino como **opiniones, lealtades y rencores**,
- el mundo del juego tiene una **memoria colectiva persistente** – la ciudad recuerda quién traicionó a quién, quién salvó a quién, quién vendió qué a quién, y todo eso afecta a los eventos futuros,
- un “AI dungeon master” aprende genuinamente tu estilo de juego, genera nuevas misiones sobre la marcha y ajusta las reglas para mantenerse desafiante pero justo,
- un servidor multijugador tiene un único **“supervisor del mundo” de IA** persistente que construye la historia del servidor junto con los jugadores durante meses y años.

Con los LLM transformers actuales podemos “hackear” parte de esto:

- guardando logs en bases de datos externas,
- metiendo *resúmenes* de encuentros anteriores en cada nuevo prompt,
- escribiendo lógica personalizada en el servidor que “pega” la memoria alrededor del modelo.

Pero escala fatal y cuesta una fortuna. Cuando tienes miles de NPC y decenas de miles de jugadores, el prompt-engineering se vuelve una pesadilla y las facturas de GPU se disparan.

Las arquitecturas post-transformer con:

- **memoria de trabajo integrada** (corto plazo) y
- **memoria estructurada a largo plazo** (grafos o estados jerárquicos)

podrían llevar a sistemas de NPC que:

- sean **mucho más baratos por instancia** (cada NPC ejecuta una pequeña “mente dragón”),
- recuerden interacciones de forma natural sin prompts hechos a mano,
- puedan aprender **a lo largo de la vida del juego** – un NPC se convierte en un “veterano experimentado” tras 200 horas de servidor, no tras el siguiente retrain en un datacenter.

Para estudios y equipos indie, esto abre la puerta a una nueva clase de juegos: **mundos vivos** que no están totalmente guionizados de antemano, sino que evolucionan junto con los jugadores.

## Qué significa para el software, los agentes y los co-pilotos

La misma lógica se aplica fuera del gaming.

Hoy, la mayoría de agentes y co-pilotos de IA son:

- **autocompletado estadístico con esteroides** – muy potente, pero sigue siendo “token a token”,
- sin continuidad real – cada herramienta de CLI, plugin de IDE o chatbot tiene que volver a explicar el contexto una y otra vez,
- con memoria “atornillada por fuera”: bases de conocimiento, búsqueda vectorial, integraciones manuales.

Un enfoque post-transformer promete:

1. **Memoria de proyecto a largo plazo**  
   Un co-piloto que recuerda cómo era tu código durante meses, y que sabe *por qué* se tomaron ciertas decisiones, no solo *cómo* está implementado.

2. **Personalización real**  
   Un asistente que se adapta a tu estilo de trabajo, hábitos, ritmo e incluso estado de ánimo, porque realmente aprende y generaliza a lo largo del tiempo.

3. **Agentes autónomos**  
   En lugar de un “agente” que recibe un prompt fresco en cada paso y olvida el anterior, tendríamos una arquitectura que puede funcionar durante días o semanas, con memoria interna y “carácter” estables.

4. **Mejor planificación y objetivos de largo horizonte**  
   Los diseños post-transformer se prestan mejor a un **planificación de varios pasos**, donde las decisiones dependen no solo del prompt actual, sino también de la historia y de las consecuencias futuras.

Para los desarrolladores, esto supone pasar de “LLM como función” a:

> **IA como proceso de larga duración dentro de tu sistema** – con memoria, hábitos e historial propios.

## No todo es Dragon: otros caminos “más allá de los transformers”

BDH no es el único proyecto que intenta ir más allá de los transformers puros.

En paralelo, aparecen otras líneas de trabajo:

- **Modelos híbridos (Transformer + SSM)**  
  Modelos como *Bamba-9B* de IBM combinan transformers con **state-space models** (tipo Mamba) para reducir la memoria y la necesidad de KV-cache manteniendo la calidad.  
  Para gaming y apps en tiempo real esto es clave: más **throughput y menor latencia**, lo que permite ejecutar más instancias de IA en el mismo hardware.

- **Modelos de razonamiento rápido para el edge**  
  Modelos pequeños e híbridos centrados en **razonamiento rápido** con 2–3× menos latencia, pensados para dispositivos con poca memoria (móviles, consolas, visores de VR).  
  Esto es directamente relevante para juegos: parte de la IA puede **vivir en el cliente**, no solo en el servidor.

- **Nuevos paradigmas de aprendizaje**  
  Conceptos como *nested learning* y trabajos similares intentan resolver el problema del **aprendizaje continuo**: cómo puede un modelo seguir aprendiendo durante toda su vida sin olvidar habilidades antiguas.  
  Es fundamental para agentes que deberían funcionar durante meses sin un “hard reset”.

- **Redes con memoria jerárquica**  
  Surgen arquitecturas que construyen explícitamente una **jerarquía de memorias** – corto, medio y largo plazo – algo así como cachés L1/L2/L3, pero para conocimiento y experiencia.

El denominador común:

> Menos redes planas y monolíticas; más **estructura, memoria y especialización**.

## Qué puede hacer hoy un desarrollador “normal”

Siendo realistas, como dev no puedes simplemente descargar “BDH 1.0” mañana y sustituir GPT en tu proyecto. Pero sí puedes preparar tu arquitectura:

1. **Separa “cerebro” y memoria desde ya**  
   Mantén conocimiento, contexto e historial en capas claras (bases de datos, grafos, event logs), en lugar de meterlo todo en el prompt.

2. **Escribe código de IA agnóstico a la arquitectura**  
   Construye adaptadores de IA que te permitan cambiar GPT-X por un futuro modelo post-transformer (BDH, híbrido SSM, etc.) sin reescribir todo el sistema.

3. **Piensa en términos de agentes, no solo de consultas**  
   Diseña sistemas donde la IA tenga un “ciclo de vida”: estado, objetivos, tareas, historia. Eso se mapeará de forma natural a arquitecturas con memoria integrada.

4. **En juegos, separa la lógica del mundo y el “cerebro de IA”**  
   Si hoy usas LLM basados en prompts para NPC, guarda la historia del mundo en estructuras separadas (BBDD gráficas, event stores), de modo que mañana puedas conectar un cerebro post-transformer que aproveche esos datos de forma eficiente.

## Conclusión

Los transformers nos han dado LLM impresionantes, pero también un techo: modelos gigantescos, GPUs carísimas, contexto limitado y prácticamente ninguna memoria real.  
Las arquitecturas post-transformer como **Baby Dragon Hatchling** intentan dar el siguiente salto: **una IA que realmente aprende y recuerda a lo largo del tiempo**, más cercana a cómo funciona un cerebro.

Para quienes construimos juegos, aplicaciones y agentes de IA, los próximos 5–10 años pueden traer:

- NPC con personalidad e historia reales, no solo un prompt de 8k tokens,
- co-pilotos que recuerdan tus proyectos durante meses en lugar de una sesión,
- agentes que se comportan como procesos de larga duración, no solo como una llamada a `complete(prompt)`.

Puede que sigamos un tiempo más en el mundo transformer, pero ya está claro que la próxima generación de IA no será solo un modelo más grande con más parámetros. Será un **tipo de mente diferente**.

> **Disclaimer:** Este texto tiene un carácter meramente informativo y no constituye asesoramiento financiero, de inversión, jurídico ni ningún otro tipo de consejo profesional.
